{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvL0uX1N5hXkcS4KxX7dcU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sofi-240/lipsRead/blob/main/NoteBookipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9trxfuLwdAB"
      },
      "outputs": [],
      "source": [
        "!pip install opencv-python matplotlib imageio gdown tensorflow\n",
        "!pip install fuzzywuzzy python-Levenshtein"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras import layers, Input\n",
        "import numpy as np\n",
        "import random\n",
        "from matplotlib import pyplot as plt\n",
        "from fuzzywuzzy import fuzz"
      ],
      "metadata": {
        "id": "VoNXcHZwwdyV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download the data\n",
        "import gdown\n",
        "gdown.download(\n",
        "    'https://drive.google.com/uc?id=1YlvpDLix3S-U8fd-gqRwPcWXAXm8JwjL',\n",
        "    'data.zip', quiet=False\n",
        ")\n",
        "gdown.extractall('/content/data.zip')\n",
        "\n",
        "gdown.download(\n",
        "    'https://drive.google.com/file/d/1uu7aIxtiVy2mPJV_PJanBOa27PyQ2jnP/view?usp=sharing',\n",
        "    '/content/data/haarcascade_frontalface_default.xml', quiet=False, fuzzy=True\n",
        ")\n",
        "\n",
        "gdown.download(\n",
        "    'https://drive.google.com/file/d/1UhfclyLFlqSQO0oCysHw5C_n5wvilO02/view?usp=sharing',\n",
        "    '/content/data/haarcascade_mcs_mouth.xml', quiet=False, fuzzy=True\n",
        ")"
      ],
      "metadata": {
        "id": "OV-fWFeNwgHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Server\n",
        "vocab = list(\"abcdefghijklmnopqrstuvwxyz'?!123456789 \")\n",
        "char2num = tf.keras.layers.StringLookup(\n",
        "    vocabulary=vocab, oov_token=\"\"\n",
        ")\n",
        "num2char = tf.keras.layers.StringLookup(\n",
        "    vocabulary=char2num.get_vocabulary(), oov_token=\"\", invert=True\n",
        ")\n",
        "\n",
        "\n",
        "def loadVideo(path):\n",
        "    cap = cv2.VideoCapture(path)\n",
        "    frames = []\n",
        "    for _ in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))):\n",
        "        _, frame = cap.read()\n",
        "        frame = cv2.cvtColor(\n",
        "            frame, cv2.COLOR_BGR2RGB\n",
        "        )\n",
        "        frames.append(\n",
        "            tf.convert_to_tensor(\n",
        "                frame\n",
        "            )\n",
        "        )\n",
        "    cap.release()\n",
        "    frames = tf.cast(\n",
        "        frames, tf.float32\n",
        "    )\n",
        "    return frames\n",
        "\n",
        "\n",
        "def loadAlignments(path):\n",
        "    with open(path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "    words = []\n",
        "    for line in lines:\n",
        "        line = line.split()\n",
        "        if line[2] != 'sil':\n",
        "            words = [*words, ' ', line[2]]\n",
        "    words = char2num(\n",
        "        tf.reshape(\n",
        "            tf.strings.unicode_split(\n",
        "                words, input_encoding='UTF-8'\n",
        "            ), (-1)\n",
        "        )\n",
        "    )[1:]\n",
        "    return words\n",
        "\n",
        "\n",
        "def loadData(path):\n",
        "    path = path.numpy().decode('utf-8')\n",
        "    fileName = path.split('/')[-1].split('.')[0]\n",
        "    videoPath = os.path.join(\n",
        "        '/content', 'data', 's1', f'{fileName}.mpg'\n",
        "    )\n",
        "    alignmentPath = os.path.join(\n",
        "        '/content', 'data', 'alignments', 's1', f'{fileName}.align'\n",
        "    )\n",
        "    frames = loadVideo(videoPath)\n",
        "    alignments = loadAlignments(alignmentPath)\n",
        "    return frames, alignments\n",
        "\n",
        "\n",
        "def mapData(path):\n",
        "    ret = tf.py_function(\n",
        "        loadData, [path], (tf.float32, tf.int64)\n",
        "    )\n",
        "    return ret\n",
        "\n",
        "\n",
        "def createPipeline():\n",
        "    def map_dir(txt):\n",
        "        if txt.split('.')[-1] == 'mpg':\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    files = os.listdir(\n",
        "        '/content/data/s1/'\n",
        "    )\n",
        "\n",
        "    files = list(\n",
        "        filter(\n",
        "            map_dir, files\n",
        "        )\n",
        "    )\n",
        "\n",
        "    data = tf.data.Dataset.from_tensor_slices(files)\n",
        "\n",
        "    data = data.shuffle(\n",
        "        len(files), reshuffle_each_iteration=False\n",
        "    )\n",
        "\n",
        "    data = data.map(\n",
        "        map_func=mapData\n",
        "    )\n",
        "\n",
        "    data = data.padded_batch(\n",
        "        2, padded_shapes=([75, None, None, 3], [40])\n",
        "    )\n",
        "\n",
        "    data = data.prefetch(\n",
        "        tf.data.AUTOTUNE\n",
        "    )\n",
        "    return data\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "O3N5I-gtF306"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Model layers\n",
        "\n",
        "\n",
        "class CTCLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self):\n",
        "        super(CTCLoss, self).__init__()\n",
        "        self.loss_function = tf.keras.backend.ctc_batch_cost\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        batch_size = tf.cast(\n",
        "            tf.shape(y_true)[0], dtype='int64'\n",
        "        )\n",
        "        input_size = tf.cast(\n",
        "            tf.shape(y_pred)[1], dtype='int64'\n",
        "        )\n",
        "        input_size = input_size * tf.ones(\n",
        "            shape=(batch_size, 1), dtype='int64'\n",
        "        )\n",
        "\n",
        "        label_size = tf.cast(\n",
        "            tf.shape(y_true)[1], dtype='int64'\n",
        "        )\n",
        "        label_size = label_size * tf.ones(\n",
        "            shape=(batch_size, 1), dtype='int64'\n",
        "        )\n",
        "\n",
        "        loss = self.loss_function(\n",
        "            y_true=y_true, y_pred=y_pred, input_length=input_size, label_length=label_size\n",
        "        )\n",
        "        return loss\n",
        "\n",
        "\n",
        "class FuzzySimilarity(tf.keras.metrics.Metric):\n",
        "    def __init__(self, name='FuzzySimilarity', **kwargs):\n",
        "        super(FuzzySimilarity, self).__init__(name=name, **kwargs)\n",
        "        self.total = self.add_weight(\n",
        "            name=\"total\", initializer=\"zeros\"\n",
        "        )\n",
        "        self.count = self.add_weight(\n",
        "            name=\"count\", initializer=\"zeros\"\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def update_state_np(y_true, y_pred):\n",
        "        decoded = tf.keras.backend.ctc_decode(\n",
        "            y_pred, [y_pred.shape[1]] * y_pred.shape[0], greedy=False\n",
        "        )[0][0].numpy()\n",
        "        y_true_str = [\n",
        "            tf.strings.reduce_join(num2char(y)).numpy().decode('utf-8') for y in y_true\n",
        "        ]\n",
        "        y_pred_str = [\n",
        "            tf.strings.reduce_join(num2char(y)).numpy().decode('utf-8') for y in decoded\n",
        "        ]\n",
        "        sim = [\n",
        "            fuzz.ratio(yt, yp) / 100 for yt, yp in zip(y_true_str, y_pred_str)\n",
        "        ]\n",
        "        return sum(sim) / 2\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        sim = tf.py_function(\n",
        "            self.update_state_np, [y_true, y_pred], tf.float32\n",
        "        )\n",
        "        self.total.assign_add(\n",
        "            tf.cast(\n",
        "                sim, self._dtype\n",
        "            )\n",
        "        )\n",
        "        self.count.assign_add(\n",
        "            tf.cast(\n",
        "                1, self._dtype\n",
        "            )\n",
        "        )\n",
        "\n",
        "    def result(self):\n",
        "        return tf.math.divide(self.total, self.count)\n",
        "\n",
        "\n",
        "class ResnetBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, filters, down_sample=True, **kwargs):\n",
        "        super(ResnetBlock, self).__init__(**kwargs)\n",
        "        self.__filters = filters\n",
        "        self.__down_sample = down_sample\n",
        "        self.__kernel_size = (3, 3, 3)\n",
        "        self.__strides = [(1, 2, 2), (1, 1, 1)] if down_sample else [(1, 1, 1), (1, 1, 1)]\n",
        "        self.__kernel_initializer = \"he_normal\"\n",
        "\n",
        "        self.identity_layers_names = []\n",
        "        self.block_layers_names = []\n",
        "\n",
        "        self.conv_1 = layers.Conv3D(\n",
        "            filters=self.__filters, kernel_size=self.__kernel_size,\n",
        "            strides=self.__strides[0], padding='same',\n",
        "            kernel_initializer=self.__kernel_initializer\n",
        "        )\n",
        "        self.bn_1 = layers.BatchNormalization()\n",
        "        self.act_1 = layers.Activation(\n",
        "            activation='relu'\n",
        "        )\n",
        "        self.block_layers_names += [\n",
        "            'conv_1', 'bn_1', 'act_1'\n",
        "        ]\n",
        "\n",
        "        self.conv_2 = layers.Conv3D(\n",
        "            filters=self.__filters, kernel_size=self.__kernel_size,\n",
        "            strides=self.__strides[1], padding='same',\n",
        "            kernel_initializer=self.__kernel_initializer\n",
        "        )\n",
        "        self.bn_2 = layers.BatchNormalization()\n",
        "        self.block_layers_names += [\n",
        "            'conv_2', 'bn_2',\n",
        "        ]\n",
        "\n",
        "        self.marge = layers.Add()\n",
        "        self.out = layers.Activation(\n",
        "            activation='relu'\n",
        "        )\n",
        "        self.block_layers_names += [\n",
        "            'marge', 'out',\n",
        "        ]\n",
        "\n",
        "        if self.__down_sample:\n",
        "            self.identity_conv = layers.Conv3D(\n",
        "                filters=self.__filters, kernel_size=(1, 1, 1),\n",
        "                strides=self.__strides[0], padding='same',\n",
        "                kernel_initializer=self.__kernel_initializer\n",
        "            )\n",
        "            self.identity_bn = layers.BatchNormalization()\n",
        "            self.identity_layers_names += [\n",
        "                'identity_conv', 'identity_bn'\n",
        "            ]\n",
        "\n",
        "    def call(self, x):\n",
        "        identity = x\n",
        "        for layer_name in self.identity_layers_names:\n",
        "            identity = self.__getattribute__(layer_name)(identity)\n",
        "\n",
        "        for layer_name in self.block_layers_names:\n",
        "            if layer_name == 'marge':\n",
        "                x = self.__getattribute__(layer_name)([identity, x])\n",
        "                continue\n",
        "            x = self.__getattribute__(layer_name)(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class ModelResNet(tf.keras.models.Model):\n",
        "    def __init__(self, input_shape, res_net_layers=10, **kwargs):\n",
        "        super(ModelResNet, self).__init__(**kwargs)\n",
        "        self.input_layer = Input(shape=input_shape, name='Input')\n",
        "        self.layers_names = []\n",
        "\n",
        "        self.prep = ModelPreprocessing(\n",
        "            input_shape=input_shape, name='prep', height=56, width=112\n",
        "        )\n",
        "\n",
        "        self.conv = layers.Conv3D(\n",
        "            filters=64, kernel_size=(1, 7, 7), padding='same', strides=(1, 1, 2),\n",
        "            kernel_initializer=\"he_normal\", name='conv'\n",
        "        )\n",
        "        self.bn = layers.BatchNormalization(name='bn')\n",
        "        self.max_pool = layers.MaxPool3D(\n",
        "            pool_size=(1, 3, 3), padding='same', strides=(1, 1, 1), name='max_pool'\n",
        "        )\n",
        "        self.layers_names += [\n",
        "            'prep', 'conv', 'bn', 'max_pool'\n",
        "        ]\n",
        "        down_sample_cond = [False] if res_net_layers == 10 else [False, False]\n",
        "\n",
        "        for block_n, filters in enumerate([64, 128, 256, 512]):\n",
        "\n",
        "            for i, sample in enumerate(down_sample_cond):\n",
        "                name = f'block{block_n + 1}_{i + 1}'\n",
        "                self.__setattr__(\n",
        "                    name,\n",
        "                    ResnetBlock(\n",
        "                        filters=filters, down_sample=sample, name=name\n",
        "                    )\n",
        "                )\n",
        "                self.layers_names += [name]\n",
        "            down_sample_cond[0] = True\n",
        "\n",
        "        self.avg = layers.AveragePooling3D(\n",
        "            pool_size=(1, 7, 7), padding='same', name='avg'\n",
        "        )\n",
        "        self.flatten = layers.TimeDistributed(\n",
        "            layers.Flatten(), name='flatten'\n",
        "        )\n",
        "        self.layers_names += [\n",
        "            'avg', 'flatten'\n",
        "        ]\n",
        "\n",
        "        for i in range(2):\n",
        "            names = [f'lstm_{i + 1}', f'drop_{i + 1}']\n",
        "            self.__setattr__(\n",
        "                names[0],\n",
        "                layers.Bidirectional(\n",
        "                    layers.LSTM(\n",
        "                        128, kernel_initializer='Orthogonal', return_sequences=True\n",
        "                    ), name=names[0]\n",
        "                )\n",
        "            )\n",
        "            self.__setattr__(\n",
        "                names[1],\n",
        "                layers.Dropout(\n",
        "                    0.5, name=names[1]\n",
        "                )\n",
        "            )\n",
        "            self.layers_names += names\n",
        "\n",
        "        self.dense = layers.Dense(\n",
        "            char2num.vocabulary_size() + 1, kernel_initializer='he_normal',\n",
        "            activation='softmax', name='dense'\n",
        "        )\n",
        "\n",
        "        self.layers_names += [\n",
        "            'dense'\n",
        "        ]\n",
        "\n",
        "        self.output_layer = self.call(self.input_layer)\n",
        "\n",
        "        super(ModelResNet, self).__init__(\n",
        "            inputs=self.input_layer,\n",
        "            outputs=self.output_layer\n",
        "        )\n",
        "\n",
        "    def call(self, x):\n",
        "        for layer_name in self.layers_names:\n",
        "            x = self.__getattribute__(layer_name)(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class ModelCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, learning_rate_base=0.01, warmup_learning_rate=1e-7, warmup_steps_practice=0.1,\n",
        "                 global_step_init=0, fuzzy_patience=5):\n",
        "        super(ModelCallback, self).__init__()\n",
        "        self.learning_rate_base = learning_rate_base\n",
        "        self.warmup_learning_rate = warmup_learning_rate\n",
        "        self.warmup_steps_practice = warmup_steps_practice\n",
        "        self.global_step = global_step_init\n",
        "        self.total_steps = None\n",
        "        self.warmup_steps = None\n",
        "        self.slope = None\n",
        "        self._built = False\n",
        "        self.fuzzy_patience = fuzzy_patience\n",
        "        self._best_fuzzy = 0\n",
        "        self._fuzzy_patience_wait = 0\n",
        "\n",
        "    def _build(self):\n",
        "        self.total_steps = int(\n",
        "            self.params['epochs'] * self.params['steps']\n",
        "        )\n",
        "        self.warmup_steps = int(\n",
        "            self.total_steps * self.warmup_steps_practice\n",
        "        )\n",
        "        self.slope = (self.learning_rate_base - self.warmup_learning_rate) / self.warmup_steps\n",
        "        self._built = True\n",
        "\n",
        "    def on_batch_end(self, batch, logs=None):\n",
        "        self.global_step = self.global_step + 1\n",
        "\n",
        "    def on_batch_begin(self, batch, logs=None):\n",
        "        if not self._built:\n",
        "            self._build()\n",
        "\n",
        "        if self.total_steps < self.warmup_steps:\n",
        "            raise ValueError(\n",
        "                'total_steps must be larger or equal to warmup_steps.'\n",
        "            )\n",
        "        if (self.warmup_steps > 0) and (self.learning_rate_base < self.warmup_learning_rate):\n",
        "            raise ValueError(\n",
        "                'learning_rate_base must be larger or equal to warmup_learning_rate.'\n",
        "            )\n",
        "\n",
        "        lr = 0.5 * self.learning_rate_base * (1 + np.cos(np.pi * (\n",
        "                (self.global_step - self.warmup_steps) / (self.total_steps - self.warmup_steps)\n",
        "        )))\n",
        "\n",
        "        if self.warmup_steps > 0:\n",
        "            warmup_rate = self.slope * self.global_step + self.warmup_learning_rate\n",
        "            lr = np.where(\n",
        "                self.global_step < self.warmup_steps, warmup_rate, lr\n",
        "            )\n",
        "        lr = np.where(\n",
        "            self.global_step > self.total_steps, 0.0, lr\n",
        "        )\n",
        "        tf.keras.backend.set_value(\n",
        "            self.model.optimizer.lr, lr\n",
        "        )\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "        logs['lr'] = float(\n",
        "            tf.keras.backend.get_value(self.model.optimizer.lr)\n",
        "        )\n",
        "        if logs.get('FuzzySimilarity') is not None:\n",
        "            fz = logs['FuzzySimilarity']\n",
        "            self._fuzzy_patience_wait += 1\n",
        "            if fz > self._best_fuzzy:\n",
        "                self._best_fuzzy = fz\n",
        "                self._fuzzy_patience_wait = 0\n",
        "            if self._fuzzy_patience_wait >= self.fuzzy_patience:\n",
        "                self.model.stop_training = True\n",
        "\n",
        "\n",
        "class ModelPreprocessing(tf.keras.layers.Layer):\n",
        "    def __init__(self, input_shape, height, width, **kwargs):\n",
        "        super(ModelPreprocessing, self).__init__(**kwargs)\n",
        "        self._out_height = height\n",
        "        self._out_width = width\n",
        "        self._out_dim = 1\n",
        "        self._output_shape = (None, input_shape[1], self._out_height, self._out_width, 1)\n",
        "        self.resize = layers.Resizing(\n",
        "            height=self._out_height, width=self._out_width,\n",
        "            interpolation='bicubic', name='resize'\n",
        "        )\n",
        "        self.rescale = layers.Rescaling(\n",
        "            scale=1. / 255, name='rescale'\n",
        "        )\n",
        "\n",
        "    def call(self, x):\n",
        "        if x.shape[0] is None:\n",
        "            x = tf.image.rgb_to_grayscale(x)\n",
        "            return tf.keras.layers.TimeDistributed(\n",
        "                self.resize\n",
        "            )(x)\n",
        "\n",
        "        x = tf.py_function(\n",
        "            self._preprocessing, [x], x.dtype\n",
        "        )\n",
        "\n",
        "        x = self.rescale(\n",
        "            x\n",
        "        )\n",
        "        return x\n",
        "\n",
        "    def _preprocessing(self, X):\n",
        "        out = np.zeros(\n",
        "            self._output_shape\n",
        "        )\n",
        "        for i, x in enumerate(X):\n",
        "            x = self._back_crop(\n",
        "                x.numpy()\n",
        "            )\n",
        "            out[i] = x\n",
        "        return tf.cast(\n",
        "            out, dtype=X.dtype\n",
        "        )\n",
        "\n",
        "    def _back_crop(self, x):\n",
        "        image_median = np.median(\n",
        "            x, axis=0\n",
        "        )\n",
        "\n",
        "        image_hsv = cv2.cvtColor(\n",
        "            image_median, cv2.COLOR_RGB2HSV\n",
        "        )\n",
        "\n",
        "        threshold, image_bin = cv2.threshold(\n",
        "            image_hsv[:, :, 0].astype(np.uint8), 0, 1, cv2.THRESH_BINARY + cv2.THRESH_OTSU\n",
        "        )\n",
        "\n",
        "        kernel = np.ones(\n",
        "            (5, 5), dtype=np.uint8\n",
        "        )\n",
        "\n",
        "        image_bin = cv2.morphologyEx(\n",
        "            image_bin, cv2.MORPH_OPEN, kernel, iterations=1\n",
        "        )\n",
        "\n",
        "        r, c = np.where(\n",
        "            image_bin == 1\n",
        "        )\n",
        "\n",
        "        boundary = [\n",
        "            [\n",
        "                c.min(), min([image_median.shape[1] - 1, c.max()])\n",
        "            ],\n",
        "            [\n",
        "                r.min(), min([image_median.shape[0] - 1, r.max()])\n",
        "            ],\n",
        "        ]\n",
        "\n",
        "        gray_frames_crop = tf.image.rgb_to_grayscale(\n",
        "            x[:, boundary[1][0]:boundary[1][1], boundary[0][0]:boundary[0][1], :]\n",
        "        ).numpy()\n",
        "        return self._face_crop(gray_frames_crop)\n",
        "\n",
        "    def _face_crop(self, x):\n",
        "        image_median = np.median(\n",
        "            x, axis=0\n",
        "        )\n",
        "        face = faceCascade(\n",
        "            contrast_stretch(image_median)\n",
        "        )\n",
        "\n",
        "        face_prop = [\n",
        "            face[0][1] - face[0][0],\n",
        "            face[1][1] - face[1][0]\n",
        "        ]\n",
        "\n",
        "        sample_index = random.sample(\n",
        "            list(\n",
        "                range(x.shape[0])\n",
        "            ), 10\n",
        "        )\n",
        "\n",
        "        for smp in sample_index:\n",
        "            curr_frame = contrast_stretch(\n",
        "                x[smp, :, :, :]\n",
        "            )\n",
        "            curr_face = faceCascade(\n",
        "                curr_frame\n",
        "            )\n",
        "            curr_prop = [\n",
        "                curr_face[0][1] - curr_face[0][0],\n",
        "                curr_face[1][1] - curr_face[1][0]\n",
        "            ]\n",
        "\n",
        "            if (curr_face[0][0] > 0 and curr_face[0][1] < curr_frame.shape[1] - 1 and curr_prop[0] > face_prop[0]) or (\n",
        "                    face_prop[0] == curr_frame.shape[1] - 1):\n",
        "                face[0] = curr_face[0]\n",
        "                face_prop[0] = curr_prop[0]\n",
        "\n",
        "            if (curr_face[1][0] > 0 and curr_face[1][1] < curr_frame.shape[0] - 1 and curr_prop[1] > face_prop[1]) or (\n",
        "                    face_prop[1] == curr_frame.shape[0] - 1):\n",
        "                face[1] = curr_face[1]\n",
        "                face_prop[1] = curr_prop[1]\n",
        "\n",
        "        gray_frames_crop = x[:, face[1][0]:face[1][1], face[0][0]:face[0][1], :]\n",
        "        return self._mouth_crop(gray_frames_crop)\n",
        "\n",
        "    def _mouth_crop(self, x):\n",
        "        image_median = np.median(\n",
        "            x, axis=0\n",
        "        )\n",
        "\n",
        "        mouth = mouthCascade(\n",
        "            contrast_stretch(image_median)\n",
        "        )\n",
        "\n",
        "        mouth_prop = [\n",
        "            mouth[0][1] - mouth[0][0],\n",
        "            mouth[1][1] - mouth[1][0]\n",
        "        ]\n",
        "\n",
        "        sample_index = random.sample(\n",
        "            list(\n",
        "                range(x.shape[0])\n",
        "            ), 10\n",
        "        )\n",
        "\n",
        "        for smp in sample_index:\n",
        "            curr_frame = contrast_stretch(\n",
        "                x[smp, :, :, :]\n",
        "            )\n",
        "            curr_mouth = mouthCascade(\n",
        "                curr_frame\n",
        "            )\n",
        "            curr_prop = [\n",
        "                curr_mouth[0][1] - curr_mouth[0][0],\n",
        "                curr_mouth[1][1] - curr_mouth[1][0]\n",
        "            ]\n",
        "\n",
        "            if (curr_mouth[0][0] > 0 and curr_mouth[0][1] < curr_frame.shape[1] - 1 and curr_prop[0] > mouth_prop[\n",
        "                0]) or (\n",
        "                    mouth_prop[0] == curr_frame.shape[1] - 1):\n",
        "                mouth[0] = curr_mouth[0]\n",
        "                mouth_prop[0] = curr_prop[0]\n",
        "\n",
        "            if (curr_mouth[1][0] > curr_frame.shape[0] // 2 and curr_prop[1] > mouth_prop[1]) or (\n",
        "                    mouth_prop[1] == (curr_frame.shape[0] // 2) - 1):\n",
        "                mouth[1] = curr_mouth[1]\n",
        "                mouth_prop[1] = curr_prop[1]\n",
        "\n",
        "        gray_frames_crop = x[:, mouth[1][0]:mouth[1][1], mouth[0][0]:mouth[0][1], :]\n",
        "        return self.resize(gray_frames_crop).numpy()\n",
        "\n",
        "\n",
        "def contrast_stretch(img_gray):\n",
        "    div = img_gray.max() - img_gray.min()\n",
        "    if div == 0:\n",
        "        return img_gray\n",
        "    img_gray = 255 * (\n",
        "            (img_gray - img_gray.min()) / div\n",
        "    )\n",
        "    return img_gray\n",
        "\n",
        "\n",
        "def faceCascade(img_gray):\n",
        "    cascade = cv2.CascadeClassifier(\n",
        "        \"data\\\\haarcascade_frontalface_default.xml\"\n",
        "    )\n",
        "\n",
        "    rect = cascade.detectMultiScale(\n",
        "        img_gray.astype(np.uint8)\n",
        "    )\n",
        "\n",
        "    if type(rect) == tuple:\n",
        "        bound = [\n",
        "            [\n",
        "                0, img_gray.shape[1] - 1\n",
        "            ],\n",
        "            [\n",
        "                0, img_gray.shape[0] - 1\n",
        "            ]\n",
        "        ]\n",
        "        return bound\n",
        "    bound = [\n",
        "        [\n",
        "            rect[0, 0], min([img_gray.shape[1] - 1, rect[0, 0] + rect[0, 2]])\n",
        "        ],\n",
        "        [\n",
        "            rect[0, 1], min([img_gray.shape[0] - 1, rect[0, 1] + rect[0, 3] + 10])\n",
        "        ],\n",
        "    ]\n",
        "    return bound\n",
        "\n",
        "\n",
        "def mouthCascade(img_gray):\n",
        "    cascade = cv2.CascadeClassifier(\n",
        "        \"data\\\\haarcascade_mcs_mouth.xml\"\n",
        "    )\n",
        "\n",
        "    rect = cascade.detectMultiScale(\n",
        "        img_gray.astype(np.uint8), 1.4\n",
        "    )\n",
        "\n",
        "    mid = img_gray.shape[0] // 2\n",
        "\n",
        "    bound = [\n",
        "        [\n",
        "            0, img_gray.shape[1] - 1\n",
        "        ],\n",
        "        [\n",
        "            mid, img_gray.shape[0] - 1\n",
        "        ]\n",
        "    ]\n",
        "\n",
        "    if type(rect) == tuple:\n",
        "        return bound\n",
        "\n",
        "    rect = rect[rect[:, 1] > mid, :]\n",
        "\n",
        "    if rect.shape[0] == 0:\n",
        "        return bound\n",
        "\n",
        "    if rect.shape[0] > 1:\n",
        "        indices = np.argsort(rect[:, 2])[::-1]\n",
        "        rect = np.reshape(\n",
        "            rect[indices[0], :], (1, 4)\n",
        "        )\n",
        "\n",
        "    bound = [\n",
        "        [\n",
        "            max([0, rect[0, 0] - 10]), min([img_gray.shape[1] - 1, rect[0, 0] + rect[0, 2] + 10])\n",
        "        ],\n",
        "        [\n",
        "            max([mid, rect[0, 1] - 10]), min([img_gray.shape[0] - 1, rect[0, 1] + rect[0, 3] + 10])\n",
        "        ],\n",
        "    ]\n",
        "    return bound\n",
        "\n"
      ],
      "metadata": {
        "id": "MruCdbtcGrBQ",
        "cellView": "form"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data = createPipeline()\n",
        "validation_size = int(0.1 * len(data))\n",
        "test_size = int(0.1 * len(data))\n",
        "\n",
        "test = data.take(test_size + validation_size)\n",
        "validation = test.take(validation_size)\n",
        "test = test.skip(validation_size)\n",
        "train = data.skip(test_size + validation_size)\n",
        "\n",
        "input_shape = data.as_numpy_iterator().next()[0][0].shape\n",
        "model = ModelResNet(input_shape)\n",
        "model.summary()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-7), loss=CTCLoss(),\n",
        "    metrics=[FuzzySimilarity()]\n",
        ")\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    os.path.join('/content', 'data', 'models', 'checkpoint'),\n",
        "    monitor='loss', save_weights_only=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "npD--Y35Ga3p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42b44a4a-050c-49ba-a6df-a5adc505a580"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_res_net_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Input (InputLayer)          [(None, 75, 288, 360, 3)  0         \n",
            "                             ]                                   \n",
            "                                                                 \n",
            " prep (ModelPreprocessing)   (None, 75, 56, 112, 1)    0         \n",
            "                                                                 \n",
            " conv (Conv3D)               (None, 75, 56, 56, 64)    3200      \n",
            "                                                                 \n",
            " bn (BatchNormalization)     (None, 75, 56, 56, 64)    256       \n",
            "                                                                 \n",
            " max_pool (MaxPooling3D)     (None, 75, 56, 56, 64)    0         \n",
            "                                                                 \n",
            " block1_1 (ResnetBlock)      (None, 75, 56, 56, 64)    221824    \n",
            "                                                                 \n",
            " block2_1 (ResnetBlock)      (None, 75, 28, 28, 128)   673664    \n",
            "                                                                 \n",
            " block3_1 (ResnetBlock)      (None, 75, 14, 14, 256)   2690816   \n",
            "                                                                 \n",
            " block4_1 (ResnetBlock)      (None, 75, 7, 7, 512)     10755584  \n",
            "                                                                 \n",
            " avg (AveragePooling3D)      (None, 75, 1, 1, 512)     0         \n",
            "                                                                 \n",
            " flatten (TimeDistributed)   (None, 75, 512)           0         \n",
            "                                                                 \n",
            " lstm_1 (Bidirectional)      (None, 75, 256)           656384    \n",
            "                                                                 \n",
            " drop_1 (Dropout)            (None, 75, 256)           0         \n",
            "                                                                 \n",
            " lstm_2 (Bidirectional)      (None, 75, 256)           394240    \n",
            "                                                                 \n",
            " drop_2 (Dropout)            (None, 75, 256)           0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 75, 41)            10537     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15,406,505\n",
            "Trainable params: 15,400,745\n",
            "Non-trainable params: 5,760\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    train, validation_data=validation, epochs=100,\n",
        "    callbacks=[checkpoint_callback, ModelCallback()]\n",
        ")\n",
        "print(model.history.history)"
      ],
      "metadata": {
        "id": "ZvXM4j-JY8oK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}